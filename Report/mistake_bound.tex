\section{Mistake Bound Model of Learning}
\begin{enumerate}


\item[1.] Each function $f_r$ in the concept class $\mathcal{C}$ is defined by a radius $r$. Since $1 \leq r \leq 80$ and $r$ is being compared with the sum of the squares of two integers, we need only consider integral values of $r$. So each function  $f_r$ in the concept class $\mathcal{C}$ that needs to be considered, will have a different integral value of $r$. So $|\mathcal{C}| = 80$.
  
\item[2.] [5 points] We need to check if the following equality is true

\begin{equation*}
y^t = \left\{
    \begin{array}{rl}
      +1 & (x_1^t)^2 + (x_2^t)^2 \leq r^2;\\
      -1 & \mbox{otherwise}
    \end{array}
\right.
\label{eq:f_r}
\end{equation*}

If it is not true then it means that the hypothesis $f_r$ has made a mistake.

\item[3.] [10 points] Consider the case when the label is $-1$ and the prediction is $+1$ because $x_1^2 + x_2^2 \leq r^2$. In order to correct this, we need to update $r$ to make it $x_1^2 + x_2^2 > r^2$ or $r = \floor*{\sqrt{x_1^2 + x_2^2 - 1}}$.\\

Consider the case when the label is $+1$ and the prediction is $-1$ because $x_1^2 + x_2^2 > r^2$. In order to correct this, we need to update $r$ to make it $r = \ceil*{\sqrt{x_1^2 + x_2^2 + 1}}$.\\

In both cases above, we need to consider only the positive value of the square root.

\item[4.] [20 points] Here is a mistake-driven learning algorithm to learn the function.

\begin{minipage}{\linewidth}
  \begin{algorithm}[H]
    \caption{Mistake-Driven Learning Algorithm}\label{MDLA}
    \begin{algorithmic}[1]
      \Procedure{Mistake-Driven Learning Algorithm}{$x_1, x_2, y$}
	\If {$x_1^2 + x_2^2 \leq r^2$}
	  \If {y == $-1$}
	    \State $r = \floor*{\sqrt{x_1^2 + x_2^2 - 1}}$
	  \EndIf
	\Else 
	  \If {y == $+1$}
	   \State $r = \ceil*{\sqrt{x_1^2 + x_2^2 + 1}}$
	  \EndIf
	\EndIf
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
\end{minipage}\\

Here the algorithm receives as input the values of $x_1$, $x_2$ and the label $y$. It then uses these values to update the value of $r$ that it maintains in its internal state. In the algorithm above, $==$ represents the test for equals and $=$ represents an assignment.

Since the correct function will use a value of $r$ between $1$ and $80$, the worst case scenario for learning the correct function will be the case where all the functions with the incorrect value of $r$ are first tried and the test data results in a wrong prediction in each such case. So the correct function will be the last one tried and will be found after making 79 (that is $\left | \mathcal{C} - 1 \right |$) mistakes. 

\item[5.] ({\bf For 6350 students})[15 points total] We have seen the
  Halving algorithm in class. The Halving algorithm will maintain a
  set of hypotheses consistent with all the examples seen so far and
  predict using the most frequent label among this set. Upon making a
  mistake, the algorithm prune at least half of this set. In this
  question, you will design and analyze a Halving algorithm for this
  particular concept space.

  \begin{enumerate}
  \item[a.] [5 points] The set of hypotheses consistent with all
    examples seen so far can be defined by storing only two integers.
    How would you do this?
  \item[b.] [5 points] How would you check if there is an error for an
    example $(x_1^t, x_2^t)$ that has the label $y^t$?
  \item[c.] [5 points] Write the full Halving algorithm for this
    specific concept space. (Do not write the same Halving algorithm
    we saw in class. You need to tailor it to this problem.) What is
    its mistake bound?
  \end{enumerate}

\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hw"
%%% End:
